{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# SETUP_ARTIFACT_PATHS\nfrom pathlib import Path\nBASE_DIR = Path.cwd().resolve()\nif BASE_DIR.name == 'notebooks':\n    BASE_DIR = BASE_DIR.parent\nMODELS_DIR = BASE_DIR / 'models'\nMAPPINGS_DIR = BASE_DIR / 'mappings'\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\nMAPPINGS_DIR.mkdir(parents=True, exist_ok=True)\nMODELO_OUT = MODELS_DIR / 'modelo_char_lm_v2.keras'\nMAPEAMENTOS_OUT = MAPPINGS_DIR / 'mapeamentos_v2.pkl'\nprint('Modelo:', MODELO_OUT)\nprint('Mapeamentos:', MAPEAMENTOS_OUT)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Como salvar artefatos (guia rápido)\nUse os caminhos padronizados definidos na célula de setup:\n- Modelo: `MODELO_OUT` (Path)\n- Mapeamentos: `MAPEAMENTOS_OUT` (Path)\n\nRecomendação prática:\n- Defina `NOME_ARQUIVO_MODELO = str(MODELO_OUT)` e `NOME_ARQUIVO_MAPS = str(MAPEAMENTOS_OUT)`\n- Use essas variáveis nas chamadas de `model.save(...)` e ao salvar/abrir mapeamentos (`open(NOME_ARQUIVO_MAPS, 'wb')`)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM v2 — Char-level Text Generator (PT-BR)\n",
    "\n",
    "Melhorias principais:\n",
    "- Embeddings de caracteres (em vez de one-hot).\n",
    "- 2 camadas LSTM maiores com dropout.\n",
    "- Callbacks (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint).\n",
    "- Amostragem com temperatura + top-k/top-p para saída mais fluida.\n",
    "- Treino a partir de um arquivo local (evita downloads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53aaef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Dropbox\\Coding\\TCC\\.venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": "import os, sys, pickle, random\nfrom pathlib import Path\nimport numpy as np\nimport tensorflow as tf\n\n# Configurações principais\nURL_LIVRO = \"https://www.gutenberg.org/files/55752/55752-0.txt\"\nNOME_ARQUIVO_MODELO = str(MODELO_OUT)\nNOME_ARQUIVO_MAPS = str(MAPEAMENTOS_OUT)\n\nSEED = 42\nSEQ_LEN = 160\nBATCH_SIZE = 128\nEPOCHS = 30\nEMBED_DIM = 128\nLSTM_UNITS = 512\nDROPOUT = 0.2\nRECURRENT_DROPOUT = 0.1  # cuidado: pode reduzir performance em GPU\nLR = 2e-3\n\n# Semente para reprodutibilidade\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce043924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do corpus: 381556\n",
      "Tamanho do vocabulário: 67\n",
      "IDs gerados: 381556\n"
     ]
    }
   ],
   "source": [
    "# Baixar os dados\n",
    "ARQUIVO_TEXTO = tf.keras.utils.get_file(\n",
    "    \"dom_casmurro.txt\", URL_LIVRO\n",
    ")\n",
    "\n",
    "# Carregar texto (UTF-8) e preparar vocabulário de caracteres\n",
    "assert Path(ARQUIVO_TEXTO).exists(), (\n",
    "    f'Arquivo {ARQUIVO_TEXTO} não encontrado. Coloque seu corpus local e rode novamente.'\n",
    ")\n",
    "with open(ARQUIVO_TEXTO, 'rb') as f:\n",
    "    texto = f.read().decode('utf-8', errors='ignore').lower()\n",
    "\n",
    "# Opcional: limpeza simples (remover controles)\n",
    "texto = ''.join(ch for ch in texto if ch == '\\n' or 32 <= ord(ch) <= 126 or ord(ch) >= 128)\n",
    "print('Tamanho do corpus:', len(texto))\n",
    "\n",
    "caracteres = sorted(list(set(texto)))\n",
    "char_to_id = {c: i for i, c in enumerate(caracteres)}\n",
    "id_to_char = {i: c for i, c in enumerate(caracteres)}\n",
    "vocab_size = len(caracteres)\n",
    "print('Tamanho do vocabulário:', vocab_size)\n",
    "\n",
    "# Codificar texto em IDs\n",
    "ids = np.fromiter((char_to_id[c] for c in texto), dtype=np.int32)\n",
    "len_ids = ids.shape[0]\n",
    "print('IDs gerados:', len_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb2a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None, None), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar dataset com tf.data\n",
    "ds = tf.data.Dataset.from_tensor_slices(ids)\n",
    "ds = ds.window(SEQ_LEN + 1, shift=1, drop_remainder=True)\n",
    "ds = ds.flat_map(lambda w: w.batch(SEQ_LEN + 1))\n",
    "def split_input_target(chunk):\n",
    "    return chunk[:-1], chunk[1:]\n",
    "ds = ds.map(split_input_target, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds = ds.shuffle(buffer_size=min(10000, len_ids)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5db07dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Carregando modelo v2 existente...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,371</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m8,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,312,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)       │        \u001b[38;5;34m34,371\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,364,747</span> (39.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,364,747\u001b[0m (39.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,454,915</span> (13.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,454,915\u001b[0m (13.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,909,832</span> (26.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,909,832\u001b[0m (26.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construir modelo com Embedding + 2x LSTM\n",
    "from tensorflow.keras import layers, optimizers, callbacks, models\n",
    "\n",
    "def build_model(vocab_size):\n",
    "    m = models.Sequential([\n",
    "        layers.Input(shape=(None,), dtype='int32'),\n",
    "        layers.Embedding(vocab_size, EMBED_DIM),\n",
    "        layers.LSTM(LSTM_UNITS, return_sequences=True, dropout=DROPOUT, recurrent_dropout=RECURRENT_DROPOUT),\n",
    "        layers.LSTM(LSTM_UNITS, return_sequences=True, dropout=DROPOUT, recurrent_dropout=RECURRENT_DROPOUT),\n",
    "        layers.Dense(vocab_size, activation='softmax'),\n",
    "    ])\n",
    "    opt = optimizers.Adam(learning_rate=LR, clipnorm=1.0)\n",
    "    m.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
    "    return m\n",
    "\n",
    "if Path(NOME_ARQUIVO_MODELO).exists() and Path(NOME_ARQUIVO_MAPS).exists():\n",
    "    print('>> Carregando modelo v2 existente...')\n",
    "    model = tf.keras.models.load_model(NOME_ARQUIVO_MODELO)\n",
    "    with open(NOME_ARQUIVO_MAPS, 'rb') as f:\n",
    "        maps = pickle.load(f)\n",
    "        char_to_id = maps['char_to_id']\n",
    "        id_to_char = maps['id_to_char']\n",
    "    vocab_size = len(char_to_id)\n",
    "    # NÃO gere novo vocabulário local!\n",
    "else:\n",
    "    print('>> Criando novo modelo v2...')\n",
    "    caracteres = sorted(list(set(texto)))\n",
    "    char_to_id = {c: i for i, c in enumerate(caracteres)}\n",
    "    id_to_char = {i: c for i, c in enumerate(caracteres)}\n",
    "    vocab_size = len(caracteres)\n",
    "    model = build_model(vocab_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad485ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'callbacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Treinamento com callbacks (pule esta célula se já possui um modelo salvo)\u001b[39;00m\n\u001b[32m      2\u001b[39m cb = [\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mcallbacks\u001b[49m.ModelCheckpoint(NOME_ARQUIVO_MODELO, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m, monitor=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      4\u001b[39m     callbacks.ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m3\u001b[39m, min_lr=\u001b[32m5e-5\u001b[39m),\n\u001b[32m      5\u001b[39m     callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m      6\u001b[39m ]\n\u001b[32m      8\u001b[39m history = model.fit(ds, epochs=EPOCHS, callbacks=cb)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Salvar mapeamentos\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'callbacks' is not defined"
     ]
    }
   ],
   "source": [
    "# Treinamento com callbacks (pule esta célula se já possui um modelo salvo)\n",
    "cb = [\n",
    "    callbacks.ModelCheckpoint(NOME_ARQUIVO_MODELO, save_best_only=True, monitor='loss', mode='min'),\n",
    "    callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=5e-5),\n",
    "    callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(ds, epochs=EPOCHS, callbacks=cb)\n",
    "\n",
    "# Salvar mapeamentos\n",
    "with open(NOME_ARQUIVO_MAPS, 'wb') as f:\n",
    "    pickle.dump({'char_to_id': char_to_id, 'id_to_char': id_to_char}, f)\n",
    "print('Treino concluído e artefatos salvos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções de geração prontas.\n"
     ]
    }
   ],
   "source": [
    "# Amostragem: temperatura + top-k + top-p (nucleus)\n",
    "def sample_next(prob, temperature=1.0, top_k=0, top_p=0.0):\n",
    "    prob = np.asarray(prob).astype('float64')\n",
    "    if prob.ndim != 1:\n",
    "        raise ValueError(\"prob must be 1D\")\n",
    "    # temperatura\n",
    "    prob = np.log(prob + 1e-9) / max(temperature, 1e-6)\n",
    "    prob = np.exp(prob)\n",
    "    prob = prob / prob.sum()\n",
    "\n",
    "    n = prob.shape[0]\n",
    "\n",
    "    # top-k (limitar k ao tamanho do vocabulário)\n",
    "    if top_k and top_k > 0:\n",
    "        k = min(int(top_k), n)\n",
    "        if k < n:\n",
    "            idx = np.argpartition(prob, -k)[-k:]\n",
    "            mask = np.zeros_like(prob)\n",
    "            mask[idx] = prob[idx]\n",
    "            denom = mask.sum()\n",
    "            if denom > 0:\n",
    "                prob = mask / denom\n",
    "\n",
    "    # top-p (nucleus)\n",
    "    if top_p and top_p > 0.0:\n",
    "        sort_idx = np.argsort(prob)[::-1]\n",
    "        sorted_prob = prob[sort_idx]\n",
    "        cumsum = np.cumsum(sorted_prob)\n",
    "        cutoff = np.searchsorted(cumsum, top_p) + 1\n",
    "        idx_keep = sort_idx[:cutoff]\n",
    "        mask = np.zeros_like(prob)\n",
    "        mask[idx_keep] = prob[idx_keep]\n",
    "        denom = mask.sum()\n",
    "        if denom > 0:\n",
    "            prob = mask / denom\n",
    "\n",
    "    return np.random.choice(n, p=prob)\n",
    "\n",
    "\n",
    "def gerar_texto_v2(model, char_to_id, id_to_char, prompt, n_chars=400, temperature=0.9, top_k=50, top_p=0.9):\n",
    "    prompt = (prompt or '').lower()\n",
    "    prompt = ''.join(c for c in prompt if c in char_to_id)\n",
    "    if not prompt:\n",
    "        prompt = ' ' if ' ' in char_to_id else list(char_to_id.keys())[0]\n",
    "\n",
    "    context_ids = [char_to_id[c] for c in prompt][-SEQ_LEN:]\n",
    "    out = [c for c in prompt]\n",
    "\n",
    "    for _ in range(n_chars):\n",
    "        x = np.array([context_ids], dtype=np.int32)\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        # pegar distribuição do último passo (protege contra saída com return_sequences)\n",
    "        if preds.ndim == 3:\n",
    "            probs = preds[0, -1]\n",
    "        elif preds.ndim == 2:\n",
    "            probs = preds[0]\n",
    "        else:\n",
    "            raise RuntimeError(\"Formato inesperado de saída do modelo\")\n",
    "        next_id = sample_next(probs, temperature=temperature, top_k=top_k, top_p=top_p)\n",
    "        next_ch = id_to_char.get(int(next_id), '')\n",
    "        out.append(next_ch)\n",
    "        context_ids.append(int(next_id))\n",
    "        if len(context_ids) > SEQ_LEN:\n",
    "            context_ids = context_ids[-SEQ_LEN:]\n",
    "    return ''.join(out)\n",
    "\n",
    "print('Funções de geração prontas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEXTO GERADO (v2) ---\n",
      "se eu contratasse uma pessoa para me ajudar a escrever nella a deus e ao diabo.\n",
      "apenas que falei desbem falar no cerebro, é provavel que a ideia\n",
      "não batesse as azas senão pela necessidade que sentia do vir ao ar e\n",
      "á vida. a vida é tão bella que a mesma ideia da morte precisa de vir\n",
      "primeiro a ella, antes de se ver cumprida. já me vás entendendo; lê\n",
      "agora outro capitulo.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cxxxiv\n",
      "\n",
      "o dia de sabbado.\n",
      "\n",
      "a ideia saiu finalmente do cerebro. era noite, e não pude dormir, por\n",
      "mais que a sacudisse de mim. tambem nenhuma noite me passou tão curta.\n",
      "amanheceu\n"
     ]
    }
   ],
   "source": [
    "# Exemplo rápido de uso (ajuste os parâmetros a gosto)\n",
    "if 'model' in globals():\n",
    "    texto = gerar_texto_v2(\n",
    "        model, char_to_id, id_to_char,\n",
    "        prompt='se eu contratasse uma pessoa para me ajudar a escrever',\n",
    "        n_chars=500, temperature=0.5, top_k=40, top_p=0.9\n",
    "    )\n",
    "    print(\"--- TEXTO GERADO (v2) ---\")\n",
    "    print(texto)\n",
    "else:\n",
    "    print('Modelo não carregado/criado. Execute as células anteriores.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}